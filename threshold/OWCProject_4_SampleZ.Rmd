---
title: "Old Woman Creek Project -- Sample Size Estimation"
author: "Song Qian"
date: "January 11, 2020"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

# Introduction 

This Rmd file includes Bayesian updating code for the Old Woman Creek project. Data used include daily monitoring data from Old Woman Creek (divided into four seasons), Crane Creek, Coldwater Creek, and Olentangy.  The code in the previous Rmd files generate necessary input data and prior distributions for model parameters. The basic principle of sample size estimation centers on the need of achieving a desirable level of certainty.  Statistical methods for sample size estimation requires (1) an understanding of the target population (particularly information about the variance), (2) a specific level of desired certainty, and (3) the statistical method to be applied to the data.  For example, when the intended statistical method is the $t$-test for a one-sample comparison problem, the planned sample size is dependent on the desired power ($1-\beta$) of detecting a specific effect size ($\delta$).  In addition, the sample size is also a function of the population variance ($\sigma^2$).  The $t$-test formula can then be used to estimate the required sample size.  

The problem of estimating the necessary sample size in a restored wetland for the purpose of estimating the wetland's phosphorus retention capacity is dependent on how we define the desired certainty or uncertainty (as in the power and effect size in the $t$-test example) and a direct link between sample size and the level of uncertainty.  These conditions require a great deal of understanding of the wetland and its phosphorus retention process, which are what we want to learn from the monitoring program.  Because we used a Monte Carlo simulation based model fitting method, the relationship between sample size and model uncertainty is not available in analytic form.  Consequently, sample size estimation can only be done using Monte Carlo simulation. However, a successful Monte Carlo simulation depends on our capability of replicate data that are representative of what we would obtain from sampling from the wetland.  That is, we must know how a wetland retains phosphorus before we can simulate the process.  Consequently, we don't expect an accurate estimation of the required sample size.  The simulation algorithm presented here is aimed to provide a conservative estimate, using the Coldwater Creek (CwC) data as an example.  

We used the initial CwC data (8 monthly means) to fit the hockey stick model. The resulting model is highly uncertain reflected in the large variance in the estimated phosphorus retention capacity.  Using this uncertain model, we simulate the actual monitoring process with a specific sample size $n$.  This is done by first drawing $n$ uniformly distributed random TP loading data within the range of the observed loading.  Then, for each loading sample we calculate the expected TP effluent concentration and its variance using the fitted model. The expected value and the variance form the predictive distribution of the effluent TP concentration at the given loading, from which we draw a random number to represent an observed log TP concentration value. With the $n$ pairs of loading and concentration values, we fit the hockey stick model and retain the MCMC samples of all estimated model coefficients.  The process is then repeated many ($k$) times.  At the end of the simulation process, we have $k$ sets of MCMC samples for each model parameter.  These $k$ sets of samples are combined to produce the posterior distributions of the estimated parameters.  By using a number of potential sample sizes, we can graphically examine how the estimation uncertainty (e.g., the width of the 95% credible interval of the posterior distributions of model parameters) decreases as sample size increases and select a desired sample size.  

If the goal of a monitoring plan is to estimate the phosphorus retention capacity of a newly restored wetland, this process allows us to develop a monitoring plan (e.g., monitoring a newly restored wetland for two years with a weekly or bi-weekly sample frequency) and update the monitoring periodically to decide whether further monitoring is necessary.  

In this document, we illustrate the process using data from CwC.  

```{r setup, include=FALSE}
## functions and setup
source("FrontMatter.R")
load("owc_data.RData")
```
## Importing Data


```{r read}
base <- getwd()
dataDIR <- paste(base, "Data", sep="/")
load("owc_data.RData")
```

Prior function from previous Rmd file

```{r}
## using the hierarchcial mdoel for the prior
prior <- function(fit, b0="B0", de="De", ph="Ph",
                  s0="sigma0",sD="sigmaD",sP="sigmaP",
                  n0=20, setn0=F){
    fit2SNprior <- rvsims(as.matrix(as.data.frame(rstan::extract(fit, permute=T))))
    
    tmp <- summary(fit2SNprior[names(fit2SNprior)==b0])
    Eb0 <- tmp$mean
    Vb0 <- tmp$sd^2
    
    tmp <- summary(fit2SNprior[names(fit2SNprior)==de])
    EDe <- tmp$mean
    VDe <- tmp$sd^2
    
    tmp <- summary(fit2SNprior[names(fit2SNprior)==ph])
    EPh <- tmp$mean
    VPh <- tmp$sd^2
    
    tmp <- summary(fit2SNprior[names(fit2SNprior)==s0]^2)
    Esigma0 <- tmp$mean
    Vsigma0 <- tmp$sd^2
    
    tmp <- summary(fit2SNprior[names(fit2SNprior)==sD]^2)
    EsigmaD <- tmp$mean
    VsigmaD <- tmp$sd^2
    
    tmp <- summary(fit2SNprior[names(fit2SNprior)==sP]^2)
    EsigmaP <- tmp$mean
    VsigmaP <- tmp$sd^2

    if (setn0) {
        alpha0 <- n0+1
        alphaD <- n0+1
        alphaP <- n0+1
    } else {
        alpha0 <- 2+Esigma0/Vsigma0
        alphaD <- 2+Esigma0/VsigmaD
        alphaP <- 2+Esigma0/VsigmaP
    }
    beta0 <- Esigma0*(alpha0-1)
    betaD <- EsigmaD*(alphaD-1)
    betaP <- EsigmaP*(alphaP-1)
    lambda0 <- Esigma0/Vb0
    lambdaD <- EsigmaD/VDe
    lambdaP <- EsigmaP/VPh
    ## limiting alpha + beta to be less than 1000
    while (alpha0+beta0 > 1000){
      alpha0 <- alpha0/10
      beta0 <- beta0/10
    }
    while (alphaD+betaD > 1000){
      alphaD <- alphaD/10
      betaD <- betaD/10
    }
    while (alphaP+betaP > 1000){
      alphaP <- alphaP/10
      betaP <- betaP/10
    }
    return(list(m0=Eb0, mD=EDe, mP=EPh,
                lmbd0=lambda0, lmbdD=lambdaD, lmbdP=lambdaP,
                al0=alpha0, alP=alphaP, alD=alphaD,
                bt0=beta0, btP=betaP, btD=betaD))
}

```

### Revised hockey stick model

The Stan model now includes a hyper-parameter for each model coefficients:

```{r}
stan_model3 <- "
	  data{
	  int N; //the number of observations
	  vector[N] y; //the response
	  vector[N] x; 

	  real theta;
          real beta1;

          real m0;
          real mD;
          real mP;

          real lmbd0;
          real lmbdD;
          real lmbdP;

          real al0;
          real alP;
          real alD;

          real bt0;
          real btP;
          real btD;

	}
	parameters {
	  real beta0; //the regression parameters
	  real<lower=0> delta;
	  real phi; //change point

	  real<lower=0> sigma;

    real mu0;
    real muD;
    real muP;

	  real<lower=0> sigma0sq;
	  real<lower=0> sigmaDsq;
	  real<lower=0> sigmaPsq;
	}
	transformed parameters {
	  vector[N] mu;
	  real<lower=0> sigma0;
	  real<lower=0> sigmaD;
	  real<lower=0> sigmaP;
	  
    sigma0 = sqrt(sigma0sq);
    sigmaD = sqrt(sigmaDsq);
    sigmaP = sqrt(sigmaPsq);
	  for (i in 1:N)
	    mu[i] = beta0 + beta1 * (x[i]-phi) +
		    delta * theta *
			    log1p(exp((x[i]-phi)/theta));
	}
	model {  
	  sigma ~ cauchy(0, 1)  ;
	  sigma0sq ~ inv_gamma(al0, bt0);
	  sigmaDsq ~ inv_gamma(alD, btD);
	  sigmaPsq ~ inv_gamma(alP, btP);
       
    mu0 ~ normal(m0, sigma0/sqrt(lmbd0));
    muD ~ normal(mD, sigmaD/sqrt(lmbdD));
    muP ~ normal(mP, sigmaP/sqrt(lmbdP));
          
	  phi ~ normal(muP, sigmaP); 
	  beta0 ~ normal(mu0, sigma0); 
	  delta ~ normal(muD, sigmaD); 

	  y ~ normal(mu, sigma);
	}
"

stan.in2 <- function(infile=owc_daily, x="maTPLD05", y="TP_ef",
                     grp=owc_daily$Quarter=="Q1", n.chains=4,
                     stdz=T,info=F, prrs = NULL){
    if (info & is.null(prrs)) stop("Need informative priors")
    infile <- infile[grp,]
    keep <- (infile[,x] > 0) & (infile[,y] >0)
    infile <- infile[keep & !is.na(keep),]
    x <- log(infile[,x])
    if (stdz){
      xmu <- mean(x, na.rm=T)
      xsd <- sd(x, na.rm=T)
      x <- (x - xmu)/xsd
    } else {
      xmu <- 0
      xsd <- 1
    }
    y <- log(infile[,y])
    n <- dim(infile)[1]
    if (info){
        m0 = prrs$m0
        mD = prrs$mD
        mP = prrs$mP
        lmbd0=prrs$lmbd0
        lmbdD=prrs$lmbdD
        lmbdP=prrs$lmbdP
        al0=prrs$al0
        alP=prrs$alP
        alD=prrs$alD
        bt0=prrs$bt0
        btP=prrs$btP
        btD=prrs$btD
    }else{
        m0 = 0
        mD = 0
        mP = 0
        lmbd0=1
        lmbdD=1
        lmbdP=1
        al0=2
        alP=2
        alD=2
        bt0=2
        btP=2
        btD=2
    }

    s0 <- sqrt(bt0/(al0-1))
    sD <- sqrt(btD/(alD-1))
    sP <- sqrt(btP/(alP-1))
    
    inits <- list()
    if (stdz) theta <- 0.04
    else theta <- 0.01*diff(range(x))
    bugs.data <- list(N=n, y=y, x=x,
                      theta=theta, beta1=0,
                      m0 = m0,  mD = mD, mP = mP,
                      lmbd0=lmbd0, lmbdD=lmbdD, lmbdP=lmbdP,
                      al0=al0, alP=alP, alD=alD,
                      bt0=bt0, btP=btP, btD=btD )
    for (i in 1:n.chains)
	inits[[i]] <- list(beta0=rnorm(1, m0, s0),
	                   delta=rnorm(1,mD,sD),
			   phi=runif(1, range(x)[1], range(x)[2]),
			   sigma=runif(1), sigmaPsq=runif(1), sigmaDsq=runif(1),
                           sigma0sq=runif(1),
                           mu0=rnorm(1, m0,s0), 
			   muD=rnorm(1, mD, sD),
                             muP=rnorm(1, mP,sP))
    para <- c("beta0", "delta", "phi","sigma",
              "mu0","muD","muP", "sigma0","sigmaD","sigmaP"
              )
    return(list(para=para, data=bugs.data, inits=inits,n.chains=n.chains,
                mux=xmu, sdx=xsd))
}

load("owcTPma05SeasonSTDZ.RData")
fit2coefSN <- rvsims(as.matrix(as.data.frame(rstan::extract(fit2, permuted=T))))

prr <- prior(fit2)

```
# Bayesian Sample Size Estimation

The following R functions implement the Monte Carlo simulation method described in the Introduction section.   

```{r}
## input file:  generating input data for the Stan model
stan.inSZ <- function(x, y, n.chains=4, prrs = prr, sz){
        n <- length(x)
        m0 = prrs$m0
        mD = prrs$mD
        mP = prrs$mP
        lmbd0=prrs$lmbd0
        lmbdD=prrs$lmbdD
        lmbdP=prrs$lmbdP
        al0=prrs$al0
        alP=prrs$alP
        alD=prrs$alD
        bt0=prrs$bt0
        btP=prrs$btP
        btD=prrs$btD
  
        s0 <- sqrt(bt0/(al0-1))
        sD <- sqrt(btD/(alD-1))
        sP <- sqrt(btP/(alP-1))
    
        inits <- list()
        theta <- 0.04
        bugs.data <- list(N=n, y=y, x=x,
                          theta=theta, beta1=0,
                          m0 = m0,  mD = mD, mP = mP,
                          lmbd0=lmbd0, lmbdD=lmbdD, lmbdP=lmbdP,
                          al0=al0, alP=alP, alD=alD,
                          bt0=bt0, btP=btP, btD=btD )
        for (i in 1:n.chains)
        	inits[[i]] <- list(beta0=rnorm(1, m0, s0),
	                           delta=runif(1),
		 	                       phi=runif(1, range(x)[1], range(x)[2]),
                    			   sigma=runif(1), sigmaPsq=runif(1),
                        		 sigmaDsq=runif(1), sigma0sq=runif(1),
                             mu0=rnorm(1, m0, s0), 
                    			   muD=rnorm(1, mD,sD),
                             muP=rnorm(1, mP, sP))
    para <- c("beta0", "delta", "phi","sigma",
              "mu0","muD","muP", "sigma0","sigmaD","sigmaP")
    return(list(para=para, data=bugs.data,
                inits=inits,n.chains=n.chains, sz=sz))
}
##cwc data -- from the saved output of theinitial run of the stan model
tmp <- cwc_month$flow!=0
load("ColdCreek_STDZ.RData")
fitcoefCWC_temp <- summary(rvsims(as.matrix(as.data.frame(rstan::extract(fitCWC, permute=T))))) ## using standardized only
fit <- stan_model(model_code = stan_model3)

## sample size - a function to simulate the sampling process

sim_sz <- function(n=12, k=100, stanmodel=fit, prior_coef=fitcoefCWC_temp){
     fitcoefSZ_sim <- list(phi=rvsims(0), 
                           beta0=rvsims(0), 
                           delta=rvsims(0))
     for (i in 1:k){
        print(paste(i, "of", k, ", sample size =", n))
        x <- rnorm(n) ## TP loading is standardized
        mnY <- hockey_smooth(x, prior_coef[1,2] , 0,
                                prior_coef[2,2] ,
                                prior_coef[3,2] ,
                                0.04)
        y <- rnorm(n, mnY, prior_coef[4,2])

        input.to.stan <- stan.inSZ(x, y, sz=n)
        fit_sim <- sampling(fit, data = input.to.stan$data,   
                            init = input.to.stan$inits,
                            pars = input.to.stan$para,
                            iter = niters, thin=nthin, 
                            chains=input.to.stan$n.chains,
                            control=list(adapt_delta = 0.99, 
                                         max_treedepth=25))
        temp_sim <-  rvsims(as.matrix(as.data.frame(rstan::extract(fit_sim, permute=T))))
        fitcoefSZ_sim$beta0 <- fitcoefSZ_sim$beta0 + temp_sim[1]/k
        fitcoefSZ_sim$delta <- fitcoefSZ_sim$delta + temp_sim[2]/k
        fitcoefSZ_sim$phi <- fitcoefSZ_sim$phi + temp_sim[3]/k
     }
     return(fitcoefSZ_sim)
}

n <- (1:15)*12  ## 10 pre-set sample sizes

smplsz_sim <- list()
for (j in 1:4)
  smplsz_sim[[j]] <- sim_sz(n=n[j])

for (j in 5:6)
  smplsz_sim[[j]] <- sim_sz(n=n[j])

for (j in 7:8)
  smplsz_sim[[j]] <- sim_sz(n=n[j])

for (j in 9:15)
  smplsz_sim[[j]] <- sim_sz(n=n[j])

save(smplsz_sim, file="CWC_SZ_sim.RData")
load("CWC_SZ_sim.RData")

```

Results are presented graphically by comparing the estimated model coefficients, especially the estimated threshold.

```{r}
sim_plot <- function(size_n=n, sim_out=smplsz_sim, para="phi"){
  j=0	
  temp <- NULL
  for (i in size_n) {
    j=j+1
    temp <- rbind(temp, c(i, unlist(summary(sim_out[[j]][[para]]))))
  }
  return (as.data.frame(temp))
}

sim_plot_phi <- sim_plot(para="phi")
sim_plot_beta0 <- sim_plot(para="beta0")
sim_plot_delta <- sim_plot(para="delta")

tikz(file="sz_sim.tex", width=6, height=4, standAlone=F)
par(mfrow=c(1,3), mar=c(4, 4, 1, 1), mgp=c(1.25,0.125, 0), 
    las=1, tck=0.01)
line.plots(sim_plot_phi$mean, sim_plot_phi$sd, 
           Xlab="Threshold (ton/yr)",
           Ylabel=sim_plot_phi[,1],
           rscale=T,
           At=log(seq(0.3, 0.8, 0.1)),
           Lab=as.character(seq(0.3,0.8,0.1)),
           V=NULL)
box()

line.plots(sim_plot_beta0$mean, sim_plot_beta0$sd, 
           Xlab="Intercept",
           Ylabel=sim_plot_beta0[,1],
           rscale=T,
           V=NULL)
box()

line.plots(sim_plot_delta$mean, sim_plot_delta$sd, 
           Xlab="Slope change",
           Ylabel=sim_plot_delta[,1],
           rscale=T,
           V=NULL)
box()

dev.off()

tikz(file="sz_simPhi.tex", width=3, height=4.75, standAlone=F)
par(mar=c(4, 4, 1, 1), mgp=c(1.25,0.125, 0), 
    las=1, tck=0.01)
line.plots(sim_plot_phi$mean, sim_plot_phi$sd, 
           Xlab="Threshold (ton/yr)",
           Ylabel=sim_plot_phi[,1],
           rscale=T,
           At=log(seq(0.3, 0.8, 0.1)),
           Lab=as.character(seq(0.3,0.8,0.1)),
           V=NULL)
box()
dev.off()

tikz(file="sz_simBeta0.tex", width=3, height=4.75, standAlone=F)
par(mar=c(4, 4, 1, 1), mgp=c(1.25,0.125, 0), 
    las=1, tck=0.01)
line.plots(sim_plot_beta0$mean, sim_plot_beta0$sd, 
           Xlab="Intercept",
           Ylabel=sim_plot_beta0[,1],
           rscale=T,
           V=NULL)
box()
dev.off()

tikz(file="sz_simDelta.tex", width=3, height=4.75, standAlone=F)
par(mar=c(4, 4, 1, 1), mgp=c(1.25,0.125, 0), 
    las=1, tck=0.01)
line.plots(sim_plot_delta$mean, sim_plot_delta$sd, 
           Xlab="Slope Change",
             Ylabel=sim_plot_delta[,1],
           rscale=T,
           V=NULL)
box()
dev.off()

```

## Interpreting and Updating Simulation Results

Based on the figures, we note that the estimation uncertainty (the width of the 90% credible interval) is visibly reduced starting from $n=48$. Further increase in sample size beyond that may not result in improved estimation.  Because the simulation model was based on the initial model fit to only eight observations, we are using a highly uncertain model.  As a result, our estimated sample size is overly conservative. We can repeat the process using the updated CwC model.

```{r}
tmp <- cwc_month$flow!=0
load("ColdCreek_STDZ_n.RData")
fitcoefCWC_temp <- summary(rvsims(as.matrix(as.data.frame(rstan::extract(fitCWC_n, permute=T))))) ## using standardized only
fit <- stan_model(model_code = stan_model3)

n <- (1:15)*12  ## 10 pre-set sample sizes

smplsz_sim_n <- list()
for (j in 1:9)
  smplsz_sim_n[[j]] <- sim_sz(n=n[j])

for (j in 10:15)
  smplsz_sim_n[[j]] <- sim_sz(n=n[j])

save(smplsz_sim_n, file="CWC_SZ_sim_n.RData")
## load("CWC_SZ_sim_n.RData")

sim_plot_phi <- sim_plot(sim_out=smplsz_sim_n, para="phi")
sim_plot_beta0 <- sim_plot(sim_out=smplsz_sim_n, para="beta0")
sim_plot_delta <- sim_plot(sim_out=smplsz_sim_n, para="delta")

tikz(file="sz_sim_n.tex", width=6, height=4, standAlone=F)
par(mfrow=c(1,3), mar=c(4, 4, 1, 1), mgp=c(1.25,0.125, 0), 
    las=1, tck=0.01)
line.plots(sim_plot_phi$mean, sim_plot_phi$sd, 
           Xlab="Threshold (ton/yr)",
           Ylabel=sim_plot_phi[,1],
           rscale=T,
           At=log(seq(0.3, 0.8, 0.1)),
           Lab=as.character(seq(0.3,0.8,0.1)),
           V=NULL)
box()

line.plots(sim_plot_beta0$mean, sim_plot_beta0$sd, 
           Xlab="Intercept",
           Ylabel=sim_plot_beta0[,1],
           rscale=T,
           V=NULL)
box()

line.plots(sim_plot_delta$mean, sim_plot_delta$sd, 
           Xlab="Slope change",
           Ylabel=sim_plot_delta[,1],
           rscale=T,
           V=NULL)
box()
dev.off()
```

